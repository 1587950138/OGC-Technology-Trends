//////
comment
//////

<<<

== Big Data (BIG)

Big data methods and techniques applied to geospatial data including the use of predictive analytics, user behavior analytics, or certain other advanced data analytics methods that extract value from data, and seldom to a particular size of data set -  (DSTL).  Big data, machine learning, and predictive data analytics allows researchers to extract insights from both scientific instruments and computational simulations (4th Paradigm) - (ACM Comm).  link:Trends/BigData.adoc[Big Geospatial Data]

<<<

[width="80%", options="header"]
|=======================
|Title      |Description

|link:Trends/StreamProcessing.adoc[Stream Processing]
|Massive data streams provide opportunities and challenges to geographic information analysis. These challenges arise because streaming data volumes cannot be subjected to analysis using the standard repertoire of methods that have been designed to analyze static geospatial datasets.


|link:Trends/WorkflowAndProvenance.adoc[Workflow and provenance]
|Provenance is information about entities, activities, and people involved in producing a piece of data or thing, which can be used to form assessments about its quality, reliability or trustworthiness - (W3C PROV).


|link:Trends/BigData.adoc[Big Geospatial Data]
|Big Data Geospatial builds upon Big Data Analytics and refers to the use of predictive analytics, user behavior analytics, or certain other advanced data analytics methods that extract value from data, and seldom to a particular size of data set -  (DSTL).  Big data, machine learning, and predictive data analytics allows researchers to extract insights from both scientific instruments and computational simulations (4th Paradigm) - (ACM Comm).


|link:Trends/ExtremeDatabases.adoc[Extremely Large Geo Databases]
|An extremely large database (XLDB) is a database that stores and processes enormous amounts of data and associated records and entries. As the largest database form factor, XLDB is created and managed by very few organizations around the world, typically scientific research institutes that have massive data sets at their disposal.

|link:Trends/EdgeIntelligenceAndFogComputing.adoc[Cloud, Fog, Edge Computing computing continuum]
|Fog computing is a system-level horizontal architecture that distributes resources and services of computing, storage, control and networking anywhere along the continuum from Cloud to Things (OpenFog Consortium).


|=======================



\
